{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e641d76-4aa7-4380-b0c3-0cea011053e2",
   "metadata": {},
   "source": [
    "# Azure AI Services Containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce4998a-4c94-4583-bbb0-eb267bdaed43",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "`Azure AI services` provide **Docker containers** that let you can keep the data closer to your host. To deploy and use an Azure AI services container, the following three activities must occur:\n",
    "\n",
    "1. The container image for the specific Azure AI services API you want to use is downloaded and deployed to a container host, such as a local Docker server, an **Azure Container Instance (ACI)**, or **Azure Kubernetes Service (AKS)**.\n",
    "2. Client applications **submit data to the endpoint** provided by the containerized service, and retrieve results just as they would from an Azure AI services cloud resource in Azure.\n",
    "3. Periodically, **usage metrics** for the containerized service are sent to an Azure AI services resource in Azure in order to calculate billing for the service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27513968-f65e-4549-acb6-099e801bb0cf",
   "metadata": {},
   "source": [
    "![image.png](./assets/ai-services-container.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00ff7521-35cc-4982-9dfb-34f56dd46923",
   "metadata": {},
   "source": [
    "this architecture gives the features and benefits below:\n",
    "* **Immutable infrastructure**:Enable DevOps teams to leverage a consistent and reliable set of known system functions. \n",
    "* **Control over data**: Choose where your data gets processed by Azure AI services\n",
    "* **Control over model updates**: Flexibility in versioning and updating of models deployed in their solutions\n",
    "* **Portable architecture**: Enables the creation of a portable application architecture that can be deployed on Azure, on-premises and the edge.\n",
    "* **High throughput & low latency**: Enabling Azure AI services to run physically close to their application logic and data.\n",
    "* **Scalability**: With the ever growing popularity of containerization and container orchestration software, such as Kubernetes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c4f1fe-c26e-4e71-bd84-ffb095f369af",
   "metadata": {},
   "source": [
    "### Install and run containers\n",
    "\n",
    "Here we use [**Document Intelligence**](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/containers/install-run?view=doc-intel-4.0.0&tabs=read) as example to demonstrate how to install and run a container via Python SDKs.<br> \n",
    "or you can visit [**Azure Official Documents**](https://learn.microsoft.com/zh-tw/azure/ai-services/cognitive-services-container-support) to get other containers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0e6b72-0a0c-4342-af82-a15e856cd742",
   "metadata": {},
   "source": [
    "#### Prerequisites\n",
    "* An Active Azure account\n",
    "* Docker Engine installed\n",
    "* Enough CPU cores and memory as below\n",
    "\n",
    "    <img src=\"./assets/system-requirements-for-documents-intelligence.png\" width=\"640\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa49937-8acd-4770-8cf3-56a1f1a7e98b",
   "metadata": {},
   "source": [
    "#### Step1. Fill the following variable and generate `docker-compose.yml` file\n",
    "* `ApiKey`: The value of this option must be set to a key for the provisioned resource specified in Billing.\n",
    "* `Billing`: The value of this option must be set to the endpoint URI of a provisioned Azure resource.\n",
    "* `Eula`: Indicates that you accepted the license for the container. The value of this option must be set to accept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "857d0469-0e04-4e9c-97b8-10fde666728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORM_RECOGNIZER_ENDPOINT_URI = 'https://ces-ai-services.cognitiveservices.azure.com/'\n",
    "FORM_RECOGNIZER_KEY = '4dfe6939ce944e77a8d5a6ede0453244'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28e2c42b-b70a-406b-a457-04c754d39296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "docker_compose_config = {\n",
    "    'version': '3.9',\n",
    "    'services':{\n",
    "        'azure-form-recognizer-read':{\n",
    "            'container_name': 'azure-form-recognizer-read',\n",
    "            'image': 'mcr.microsoft.com/azure-cognitive-services/form-recognizer/read-3.1',\n",
    "            'environment':[\n",
    "                'EULA=accept', \n",
    "                f'billing={FORM_RECOGNIZER_ENDPOINT_URI}', \n",
    "                f'apiKey={FORM_RECOGNIZER_KEY}'],\n",
    "            'ports':['5000:5000'],\n",
    "            'networks':['ocrvnet']\n",
    "        }\n",
    "    },\n",
    "    'networks':{\n",
    "        'ocrvnet':{\n",
    "            'driver': 'bridge'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "with open('docker-compose.yml', 'w') as f:\n",
    "    yaml.dump(docker_compose_config, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f978ea4-cee6-4fd3-8d8a-d94deb5d0f9d",
   "metadata": {},
   "source": [
    "#### Step2. Start the service with the docker compose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d09ca57-bf77-4911-9d1d-b144dad79365",
   "metadata": {},
   "source": [
    "run `docker-compose up` in your Terminal or Command Line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c6085b-1dee-47c4-98f9-e3797390028f",
   "metadata": {},
   "source": [
    "#### Step3. Validate that the service is running"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a6d180-6c28-4569-89a3-3b859ccf291e",
   "metadata": {},
   "source": [
    "a. Open a new browser tab and use the IP address `http://localhost:5000`<br>\n",
    "b. Select **Service API Description** to view the swagger page, and select any of the POST APIs and select Try it out<br><br>\n",
    "    <img src=\"./assets/navigator-for-container.png\" width=\"640\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426e644d-3e2a-4abe-a5f0-632671e8b7d8",
   "metadata": {},
   "source": [
    "# Appendix - Available Containers<sub> (2024/10 updated)| |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4785f5-2bcb-4321-8bc7-04506421e017",
   "metadata": {},
   "source": [
    "### Language containers\n",
    "|  Service   | Description  | Availability  |\n",
    "|  --------  | -----------  | ------------- |\n",
    "| Key Phrase Extraction | Extracts key phrases to identify the main points. | Generally Available. Support for disconnected runtime |\n",
    "| Text Language Detection | For up to 120 languages, detects which language the input text is written in and report a single language code for every document submitted on the request.  |  Generally Available. Support for disconnected runtime|\n",
    "| Sentiment Analysis | Analyzes raw text for clues about positive or negative sentiment. This version of sentiment analysis returns sentiment labels | Generally Available. Support for disconnected runtime |\n",
    "| Text Analytics for health | Extract and label medical information from unstructured clinical text. | Generally Available. |\n",
    "| Named Entity Recognition | Extract named entities from text. | Generally Available. Support for disconnected runtime |\n",
    "| Custom Named Entity Recognition | Extract named entities from text, using a custom model you create using your data. | Generally Available. |\n",
    "| Summarization | Summarize text from various sources.\t | Generally Available. Support for disconnected runtime |\n",
    "| ranslator | Translate text in several languages and dialects. | Generally Available. Support for disconnected runtime |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7bd1ad-9a7f-4984-a3c6-a75742491035",
   "metadata": {},
   "source": [
    "### Speech containers\n",
    "|  Service   | Description  | Availability  |\n",
    "|  --------  | -----------  | ------------- |\n",
    "| Speech to text  | Transcribes continuous real-time speech into text.| Generally Available. Support for disconnected runtime|\n",
    "| Custom Speech to text  | Transcribes continuous real-time speech into text using a custom model. | Generally Available. Support for disconnected runtime |\n",
    "| Neural Text to speech  | Converts text to natural-sounding speech using deep neural network technology, allowing for more natural synthesized speech. | Generally Available. Support for disconnected runtime|\n",
    "| Speech language identification | Determines the language of spoken audio. | Preview |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cba6a82-6f89-4358-80e5-b5e86aa8b542",
   "metadata": {},
   "source": [
    "### Vision containers\n",
    "|  Service   | Description  | Availability  |\n",
    "|  --------  | -----------  | ------------- |\n",
    "| Read OCR  | Extract printed and handwritten text from images and documents, support for `JPEG`, `PNG`, `BMP`, `PDF`, and `TIFF` file formats.| Generally Available. Support for disconnected runtime |\n",
    "| Spatial analysis | Analyzes real-time streaming video to understand spatial relationships between people, their movement, and interactions with objects in physical. | Preview |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa904ba6-13fa-48f7-a1f6-74fc61fe7c15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
